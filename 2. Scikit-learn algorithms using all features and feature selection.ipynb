{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sort\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import SelectPercentile,f_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\Hannah\\Desktop\\Research Project\\data.csv\")\n",
    "data = data.drop([\"Unnamed: 32\", \"id\"],1)\n",
    "#includes all features from columns also floats and normalizes them\n",
    "\n",
    "X = data.values[:,1:-1].astype('float64') #assures data is same type/format\n",
    "#X = (X - np.mean(X, axis =0)) /  np.std(X, axis = 0) #from scratch scaling\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "Y = data[\"diagnosis\"].map({'M':1,'B':0})\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All LR feature weights:\n",
      "[ 0.69310273  0.74889515  0.76485112  0.99703253 -0.21488682  0.55437203\n",
      "  1.64248906  2.33456278  0.04669199 -1.30159327  1.28968424 -0.36301494\n",
      "  1.00535739  0.88130844 -0.67541026 -0.72874247 -0.48697947 -0.3022146\n",
      " -0.51553419 -0.68374043  1.57371518  1.27606352  1.4843543   1.41841259\n",
      "  0.62653777  0.90772302  1.25292759  2.36548035  0.88320209]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK6VUG/r/AUBfsFcmubZ8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2016dee5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0) #splitting data randomly\n",
    "\n",
    "#naming all classifiers from their imports\n",
    "svm = SVC()\n",
    "rfc =RandomForestClassifier()\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "nb = GaussianNB()\n",
    "mlp = MLPClassifier(max_iter=250, learning_rate_init=0.1)\n",
    "\n",
    "#Viewing LR coefficients\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print('All LR feature weights:')\n",
    "coef=logreg.coef_[0]\n",
    "print(coef)\n",
    "plt.plot(X, Y)\n",
    "plt.plot(coef)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with all features:\n",
      "\n",
      "\n",
      "SVM scikit-learn accuracy: 95.80 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.90697674  0.96511628  0.92941176  0.96470588  0.94047619]\n",
      "Accuracy: 0.94 (+/- 0.04)\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.94      1.00      0.97        90\n",
      "  Malignant       1.00      0.89      0.94        53\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n",
      "RFC scikit-learn accuracy: 98.60 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.94186047  0.95348837  0.94117647  0.98823529  0.96428571]\n",
      "Accuracy: 0.96 (+/- 0.03)\n",
      "Confusion Matrix:\n",
      "[[89  1]\n",
      " [ 1 52]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.99      0.99      0.99        90\n",
      "  Malignant       0.98      0.98      0.98        53\n",
      "\n",
      "avg / total       0.99      0.99      0.99       143\n",
      "\n",
      "DT scikit-learn accuracy: 88.81 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.91860465  0.88372093  0.95294118  0.90588235  0.91666667]\n",
      "Accuracy: 0.92 (+/- 0.04)\n",
      "Confusion Matrix:\n",
      "[[77 13]\n",
      " [ 3 50]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.99      0.99      0.99        90\n",
      "  Malignant       0.98      0.98      0.98        53\n",
      "\n",
      "avg / total       0.99      0.99      0.99       143\n",
      "\n",
      "NB scikit-learn accuracy: 92.31 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.94186047  0.95348837  0.92941176  0.95294118  0.96428571]\n",
      "Accuracy: 0.95 (+/- 0.02)\n",
      "Confusion Matrix:\n",
      "[[85  5]\n",
      " [ 6 47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.93      0.94      0.94        90\n",
      "  Malignant       0.90      0.89      0.90        53\n",
      "\n",
      "avg / total       0.92      0.92      0.92       143\n",
      "\n",
      "MLP scikit-learn accuracy: 95.80 %\n",
      "Cross Validation Accuracy:\n",
      "[ 1.          0.98837209  0.95294118  0.98823529  0.97619048]\n",
      "Accuracy: 0.98 (+/- 0.03)\n",
      "Confusion Matrix:\n",
      "[[87  3]\n",
      " [ 3 50]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.97      0.97      0.97        90\n",
      "  Malignant       0.94      0.94      0.94        53\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n",
      "LR scikit-learn accuracy: 95.10 %\n",
      "[ 0.91860465  0.96511628  0.94117647  0.96470588  1.        ]\n",
      "Accuracy: 0.96 (+/- 0.05)\n",
      "Confusion Matrix:\n",
      "[[90  0]\n",
      " [ 7 46]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.93      1.00      0.96        90\n",
      "  Malignant       1.00      0.87      0.93        53\n",
      "\n",
      "avg / total       0.95      0.95      0.95       143\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############### All Features with Scikit-learn Algoritms #################################\n",
    "\n",
    "print('Accuracy with all features:')\n",
    "print('\\n')\n",
    "\n",
    "#training algorithm\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "#using test dataset for predictive accuracy\n",
    "print('SVM scikit-learn accuracy: {:.2f}'.format(svm.score(X_test, Y_test)*100),  '%')\n",
    "\n",
    "#cross-validation (not used results)\n",
    "scores = cross_val_score(svm, X_train, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "#performing the predictions function to build the confusion matrix\n",
    "predictions = svm.predict(X_test)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "cm = confusion_matrix(Y_test, predictions)\n",
    "\n",
    "#Classification report for F1 scoring\n",
    "target_names = ['Benign', 'Malignant']\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "\n",
    "rfc.fit(X_train, Y_train)\n",
    "print('RFC scikit-learn accuracy: {:.2f}'.format(rfc.score(X_test, Y_test)*100),  '%')\n",
    "scores = cross_val_score(rfc, X_train, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"Confusion Matrix:\")\n",
    "predictions2 = rfc.predict(X_test)\n",
    "print(confusion_matrix(Y_test, predictions2))\n",
    "print(classification_report(Y_test, predictions2, target_names=target_names))\n",
    "\n",
    "dt.fit(X_train, Y_train)\n",
    "print('DT scikit-learn accuracy: {:.2f}'.format(dt.score(X_test, Y_test)*100),  '%')\n",
    "scores = cross_val_score(dt, X_train, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"Confusion Matrix:\")\n",
    "predictions25 = dt.predict(X_test)\n",
    "print(confusion_matrix(Y_test, predictions25))\n",
    "print(classification_report(Y_test, predictions2, target_names=target_names))\n",
    "\n",
    "\n",
    "nb.fit(X_train, Y_train)\n",
    "print('NB scikit-learn accuracy: {:.2f}'.format(nb.score(X_test, Y_test)*100),  '%')\n",
    "scores = cross_val_score(nb, X_train, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"Confusion Matrix:\")\n",
    "predictions3 = nb.predict(X_test)\n",
    "print(confusion_matrix(Y_test, predictions3))\n",
    "print(classification_report(Y_test, predictions3, target_names=target_names))\n",
    "\n",
    "mlp.fit(X_train, Y_train)\n",
    "print('MLP scikit-learn accuracy: {:.2f}'.format(mlp.score(X_test, Y_test)*100),  '%')\n",
    "scores = cross_val_score(mlp, X_train, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"Confusion Matrix:\")\n",
    "predictions5 = mlp.predict(X_test)\n",
    "print(confusion_matrix(Y_test, predictions5))\n",
    "print(classification_report(Y_test, predictions5, target_names=target_names))\n",
    "\n",
    "\n",
    "logreg.fit(X_train, Y_train)\n",
    "print('LR scikit-learn accuracy: {:.2f}'.format(logreg.score(X_test, Y_test)*100),  '%')\n",
    "scores = cross_val_score(logreg, X_train, Y_train, cv=5)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"Confusion Matrix:\")\n",
    "predictions5 = logreg.predict(X_test)\n",
    "print(confusion_matrix(Y_test, predictions5))\n",
    "print(classification_report(Y_test, predictions5, target_names=target_names))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Feature Selection:\n",
      "X_train shape is: (426, 29)\n",
      "(30 features range from 0-29 due to Python language)\n",
      "X_train feature selected shape is: (426, 3)\n",
      "\n",
      " These selected features are:\n",
      "[False False False False False False False  True False False False False\n",
      " False False False False False False False False False False  True False\n",
      " False False False  True False]\n",
      "[ 7 22 27]\n",
      "All SelectPercentile p-values from lowest to highest\n",
      "[  2.90246801e-94   8.98762428e-87   3.08095116e-86   3.11012794e-84\n",
      "   8.19690935e-73   1.18230031e-69   2.55823842e-69   1.48052645e-62\n",
      "   1.45377554e-60   2.92390622e-54   9.49913611e-45   1.24060859e-43\n",
      "   7.43308506e-36   4.06310902e-34   1.36320509e-31   5.36444219e-22\n",
      "   8.87987480e-21   3.75876060e-20   8.37108067e-18   1.27734112e-15\n",
      "   1.29817853e-15   3.44436651e-13   2.94961572e-08   1.07859166e-04\n",
      "   6.41875480e-02   2.69973265e-01   4.97932018e-01   5.41630631e-01\n",
      "   6.30247708e-01]\n",
      "Feature column number's p-values from lowest to highest\n",
      "[27  7 22 20  2 23  0  3  6 26  5 25 10 12 13 21 24 28  1  4 17  8 15 16 14\n",
      " 19 11 18  9]\n",
      "Top 10 Percentile Selected (highest to lowest) :\n",
      "27 - concave points_worst, 7 - concave points_mean, 22 - perimeter_worst\n",
      "\n",
      "\n",
      "Accuracy with Top 10 Percentile feature selection:\n",
      "SVM scikit-learn accuracy: 94.41 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.90697674  0.94186047  0.92941176  0.95294118  0.92857143]\n",
      "Accuracy: 0.93 (+/- 0.03)\n",
      "[[89  1]\n",
      " [ 7 46]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.93      0.99      0.96        90\n",
      "  Malignant       0.98      0.87      0.92        53\n",
      "\n",
      "avg / total       0.95      0.94      0.94       143\n",
      "\n",
      "RFC scikit-learn accuracy: 95.10 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.90697674  0.90697674  0.91764706  0.94117647  0.94047619]\n",
      "Accuracy: 0.92 (+/- 0.03)\n",
      "[[88  2]\n",
      " [ 5 48]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.95      0.98      0.96        90\n",
      "  Malignant       0.96      0.91      0.93        53\n",
      "\n",
      "avg / total       0.95      0.95      0.95       143\n",
      "\n",
      "NB scikit-learn accuracy: 94.41 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.90697674  0.96511628  0.94117647  0.94117647  0.96428571]\n",
      "Accuracy: 0.94 (+/- 0.04)\n",
      "[[88  2]\n",
      " [ 6 47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.94      0.98      0.96        90\n",
      "  Malignant       0.96      0.89      0.92        53\n",
      "\n",
      "avg / total       0.94      0.94      0.94       143\n",
      "\n",
      "DT scikit-learn accuracy: 93.01 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.90697674  0.93023256  0.91764706  0.90588235  0.91666667]\n",
      "Accuracy: 0.92 (+/- 0.02)\n",
      "[[84  6]\n",
      " [ 4 49]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.95      0.93      0.94        90\n",
      "  Malignant       0.89      0.92      0.91        53\n",
      "\n",
      "avg / total       0.93      0.93      0.93       143\n",
      "\n",
      "MLP scikit-learn accuracy: 94.41 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.91860465  0.95348837  0.94117647  0.95294118  0.95238095]\n",
      "Accuracy: 0.94 (+/- 0.03)\n",
      "[[88  2]\n",
      " [ 6 47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.94      0.98      0.96        90\n",
      "  Malignant       0.96      0.89      0.92        53\n",
      "\n",
      "avg / total       0.94      0.94      0.94       143\n",
      "\n",
      "LR scikit-learn accuracy: 94.41 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.90697674  0.94186047  0.92941176  0.95294118  0.94047619]\n",
      "Accuracy: 0.93 (+/- 0.03)\n",
      "[[89  1]\n",
      " [ 7 46]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.93      0.99      0.96        90\n",
      "  Malignant       0.98      0.87      0.92        53\n",
      "\n",
      "avg / total       0.95      0.94      0.94       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############### SelectFromPercentile Features #################################\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "#SelectPercentile function within select:\n",
    "select = feature_selection.SelectPercentile(f_classif, percentile=10)\n",
    "#Carrying out feature selection using select on the training data and transforming it to the test data\n",
    "selected = select.fit(X_train, Y_train)\n",
    "X_train_selected = selected.transform(X_train)\n",
    "X_test_selected = selected.transform(X_test)\n",
    "\n",
    "#Identifying features selected\n",
    "print('Scikit-learn Feature Selection:')\n",
    "print('X_train shape is: {}'.format(X_train.shape))\n",
    "print('(30 features range from 0-29 due to Python language)')\n",
    "print('X_train feature selected shape is: {}'.format(X_train_selected.shape))\n",
    "print(\"\\n\", \"These selected features are:\")\n",
    "\n",
    "#Getting the feature number of the features selected\n",
    "#also printing all features identifying with \"false\" for not selected and \"true\" for selected\n",
    "#Match the true features to their number to get their feature names\n",
    "mask = select.get_support()\n",
    "print(mask)\n",
    "idxs_selected = select.get_support(indices=True)\n",
    "print(idxs_selected)\n",
    "print(\"All SelectPercentile p-values from lowest to highest\")\n",
    "#using p-value to order feature importance\n",
    "p_value= np.sort(selected.pvalues_)\n",
    "p_valuenames = np.argsort(selected.pvalues_)\n",
    "print(p_value)\n",
    "print(\"Feature column number's p-values from lowest to highest\")\n",
    "print(p_valuenames)\n",
    "\n",
    "print(\"Top 10 Percentile Selected (highest to lowest) :\")\n",
    "print('27 - concave points_worst, 7 - concave points_mean, 22 - perimeter_worst')\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "############### SelectPercentile with Scikit-learn Algoritms #################################\n",
    "print('Accuracy with Top 10 Percentile feature selection:')\n",
    "\n",
    "selected = select.fit(X_train, Y_train)\n",
    "X_train_selected = selected.transform(X_train)\n",
    "X_test_selected = selected.transform(X_test)\n",
    "\n",
    "svm.fit(X_train_selected, Y_train)\n",
    "print('SVM scikit-learn accuracy: {:.2f}'.format(svm.score(X_test_selected, Y_test)*100),  '%')\n",
    "scores = cross_val_score(svm, X_train_selected, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predictions = svm.predict(X_test_selected)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "\n",
    "rfc.fit(X_train_selected, Y_train)\n",
    "print('RFC scikit-learn accuracy: {:.2f}'.format(rfc.score(X_test_selected, Y_test)*100),  '%')\n",
    "scores = cross_val_score(rfc, X_train_selected, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predictions = rfc.predict(X_test_selected)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "\n",
    "nb.fit(X_train_selected, Y_train)\n",
    "print('NB scikit-learn accuracy: {:.2f}'.format(nb.score(X_test_selected, Y_test)*100),  '%')\n",
    "scores = cross_val_score(nb, X_train_selected, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predictions = nb.predict(X_test_selected)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "\n",
    "dt.fit(X_train_selected, Y_train)\n",
    "print('DT scikit-learn accuracy: {:.2f}'.format(dt.score(X_test_selected, Y_test)*100),  '%')\n",
    "scores = cross_val_score(dt, X_train_selected, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predictions = dt.predict(X_test_selected)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "\n",
    "mlp.fit(X_train_selected, Y_train)\n",
    "print('MLP scikit-learn accuracy: {:.2f}'.format(mlp.score(X_test_selected, Y_test)*100),  '%')\n",
    "scores = cross_val_score(mlp,X_train_selected, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predictions = mlp.predict(X_test_selected)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "\n",
    "logreg.fit(X_train_selected, Y_train)\n",
    "print('LR scikit-learn accuracy: {:.2f}'.format(logreg.score(X_test_selected, Y_test)*100),  '%')\n",
    "scores = cross_val_score(logreg,X_train_selected, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predictions = logreg.predict(X_test_selected)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train feature selected shape is: (426, 10)\n",
      "(30 features range from 0-29 due to Python language)\n",
      "Selected 10 (k) feature column numbers with chi2\n",
      "[ True False  True  True False False  True  True False False False False\n",
      " False False False False False False False False  True False  True  True\n",
      " False False  True  True False]\n",
      "[ 0  2  3  6  7 20 22 23 26 27]\n",
      "All Chi2 ranking p-values using selectkbest\n",
      "[  2.90246801e-94   8.98762428e-87   3.08095116e-86   3.11012794e-84\n",
      "   8.19690935e-73   1.18230031e-69   2.55823842e-69   1.48052645e-62\n",
      "   1.45377554e-60   2.92390622e-54   9.49913611e-45   1.24060859e-43\n",
      "   7.43308506e-36   4.06310902e-34   1.36320509e-31   5.36444219e-22\n",
      "   8.87987480e-21   3.75876060e-20   8.37108067e-18   1.27734112e-15\n",
      "   1.29817853e-15   3.44436651e-13   2.94961572e-08   1.07859166e-04\n",
      "   6.41875480e-02   2.69973265e-01   4.97932018e-01   5.41630631e-01\n",
      "   6.30247708e-01]\n",
      "Selected 10 (k) p-values from lowest to highest:\n",
      "[27  7 22 20  2 23  0  3  6 26  5 25 10 12 13 21 24 28  1  4 17  8 15 16 14\n",
      " 19 11 18  9]\n",
      "Selected 10 top ranked from highest to lowest:\n",
      "27 - concave points_worst 7 - concave points_mean 22 - perimeter_worst 20 - radius_worst 2 - perimeter_mean 23 - area_worst 0 - radius_mean  3 - area_mean 6 -  concavity_mean 26 - concavity_worst\n",
      "\n",
      "\n",
      "The scikit-learn accuracy of SVM: 95.80 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.88372093  0.93023256  0.94117647  0.92941176  0.97619048]\n",
      "CV Accuracy: 0.93 (+/- 0.06)\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.94      1.00      0.97        90\n",
      "  Malignant       1.00      0.89      0.94        53\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n",
      "The scikit-learn accuracy of RFC: 96.50 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.93023256  0.94186047  0.91764706  0.94117647  0.97619048]\n",
      "CV Accuracy: 0.94 (+/- 0.04)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.94      1.00      0.97        90\n",
      "  Malignant       1.00      0.89      0.94        53\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n",
      "[[88  2]\n",
      " [ 3 50]]\n",
      "The scikit-learn accuracy of DT: 93.01 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.87209302  0.95348837  0.90588235  0.91764706  0.92857143]\n",
      "CV Accuracy: 0.92 (+/- 0.05)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.97      0.98      0.97        90\n",
      "  Malignant       0.96      0.94      0.95        53\n",
      "\n",
      "avg / total       0.96      0.97      0.96       143\n",
      "\n",
      "[[84  6]\n",
      " [ 4 49]]\n",
      "The scikit-learn accuracy of NB: 95.80 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.93023256  0.93023256  0.91764706  0.94117647  0.98809524]\n",
      "CV Accuracy: 0.94 (+/- 0.05)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.95      0.93      0.94        90\n",
      "  Malignant       0.89      0.92      0.91        53\n",
      "\n",
      "avg / total       0.93      0.93      0.93       143\n",
      "\n",
      "[[86  4]\n",
      " [ 2 51]]\n",
      "The scikit-learn accuracy of MLP: 95.80 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.96511628  0.95348837  0.91764706  0.95294118  0.97619048]\n",
      "CV Accuracy: 0.95 (+/- 0.04)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.98      0.96      0.97        90\n",
      "  Malignant       0.93      0.96      0.94        53\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "The scikit-learn accuracy of LR: 94.41 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.88372093  0.93023256  0.95294118  0.94117647  0.97619048]\n",
      "CV Accuracy: 0.94 (+/- 0.06)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.94      1.00      0.97        90\n",
      "  Malignant       1.00      0.89      0.94        53\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n",
      "[[88  2]\n",
      " [ 6 47]]\n"
     ]
    }
   ],
   "source": [
    "######################### SelectKBest, chi2 Features ###################################################\n",
    "#Implementing SelectKBest with chi2 as \"select\"\n",
    "select = feature_selection.SelectKBest(chi2, k=10)\n",
    "selected2 = select.fit(X_train, Y_train)\n",
    "#Carrying out feature selection using \"select\" on the training data and transforming it to the test data\n",
    "X_train_selected2 = selected2.transform(X_train)\n",
    "X_test_selected2 = selected2.transform(X_test)\n",
    "print('X_train feature selected shape is: {}'.format(X_train_selected2.shape))\n",
    "print('(30 features range from 0-29 due to Python language)')\n",
    "\n",
    "#Getting the feature number of the features selected\n",
    "#also printing all features identifying with \"false\" for not selected and \"true\" for selected\n",
    "#Match the true features to their number to get their feature names\n",
    "mask = selected2.get_support()\n",
    "print('Selected 10 (k) feature column numbers with chi2')\n",
    "print(mask)\n",
    "idxs_selected = selected2.get_support(indices=True)\n",
    "print(idxs_selected)\n",
    "#Using p-value to rank feature importance from the selection method\n",
    "print(\"All Chi2 ranking p-values using selectkbest\")\n",
    "pvalue= np.sort(selected.pvalues_)\n",
    "pvaluenames = np.argsort(selected.pvalues_)\n",
    "print(pvalue)\n",
    "print(\"Selected 10 (k) p-values from lowest to highest:\")\n",
    "print(pvaluenames)\n",
    "print(\"Selected 10 top ranked from highest to lowest:\")\n",
    "print('27 - concave points_worst',\n",
    "       '7 - concave points_mean',\n",
    "      '22 - perimeter_worst',\n",
    "      '20 - radius_worst',\n",
    "      '2 - perimeter_mean' ,\n",
    "      '23 - area_worst',\n",
    "      '0 - radius_mean ',\n",
    "      '3 - area_mean', \n",
    "      '6 -  concavity_mean',\n",
    "     '26 - concavity_worst')\n",
    "\n",
    "\n",
    "############### SelectKBest with Scikit-learn Algoritms #################################\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "svm.fit(X_train_selected2, Y_train)\n",
    "print('The scikit-learn accuracy of SVM: {:.2f}'.format(svm.score(X_test_selected2, Y_test)*100),  '%')\n",
    "scores = cross_val_score(svm, X_train_selected2, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predictions = svm.predict(X_test_selected2)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "\n",
    "rfc.fit(X_train_selected2, Y_train)\n",
    "print('The scikit-learn accuracy of RFC: {:.2f}'.format(rfc.score(X_test_selected2, Y_test)*100),  '%')\n",
    "scores = cross_val_score(rfc, X_train_selected2, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = rfc.predict(X_test_selected2)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "dt.fit(X_train_selected2, Y_train)\n",
    "print('The scikit-learn accuracy of DT: {:.2f}'.format(dt.score(X_test_selected2, Y_test)*100),  '%')\n",
    "scores = cross_val_score(dt, X_train_selected2, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = dt.predict(X_test_selected2)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "nb.fit(X_train_selected2, Y_train)\n",
    "print('The scikit-learn accuracy of NB: {:.2f}'.format(nb.score(X_test_selected2, Y_test)*100),  '%')\n",
    "scores = cross_val_score(nb, X_train_selected2, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = nb.predict(X_test_selected2)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "mlp.fit(X_train_selected2, Y_train)\n",
    "print('The scikit-learn accuracy of MLP: {:.2f}'.format(mlp.score(X_test_selected2, Y_test)*100),  '%')\n",
    "scores = cross_val_score(mlp, X_train_selected2, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = mlp.predict(X_test_selected2)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "logreg.fit(X_train_selected2, Y_train)\n",
    "print('The scikit-learn accuracy of LR: {:.2f}'.format(logreg.score(X_test_selected2, Y_test)*100),  '%')\n",
    "scores = cross_val_score(logreg, X_train_selected2, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = logreg.predict(X_test_selected2)\n",
    "print(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train feature selected shape is: (426, 10)\n",
      "(30 features range from 0-29 due to Python language)\n",
      "Selected 10 (k) feature column numbers with ANOVA F-values:\n",
      "[ True False  True  True False False  True  True False False False False\n",
      " False False False False False False False False  True False  True  True\n",
      " False False  True  True False]\n",
      "[ 0  2  3  6  7 20 22 23 26 27]\n",
      "Feature p-values with ANOVA selectkbest\n",
      "[  2.90246801e-94   8.98762428e-87   3.08095116e-86   3.11012794e-84\n",
      "   8.19690935e-73   1.18230031e-69   2.55823842e-69   1.48052645e-62\n",
      "   1.45377554e-60   2.92390622e-54   9.49913611e-45   1.24060859e-43\n",
      "   7.43308506e-36   4.06310902e-34   1.36320509e-31   5.36444219e-22\n",
      "   8.87987480e-21   3.75876060e-20   8.37108067e-18   1.27734112e-15\n",
      "   1.29817853e-15   3.44436651e-13   2.94961572e-08   1.07859166e-04\n",
      "   6.41875480e-02   2.69973265e-01   4.97932018e-01   5.41630631e-01\n",
      "   6.30247708e-01]\n",
      "Feature p-values ranked from lowest to highest:\n",
      "[27  7 22 20  2 23  0  3  6 26  5 25 10 12 13 21 24 28  1  4 17  8 15 16 14\n",
      " 19 11 18  9]\n",
      "10 (k) selected features from most to least significant:\n",
      "27 - concave points_worst 7 - concave points_mean 22 - perimeter_worst 20 - radius_worst 2 - perimeter_mean 23 - area_worst 0 - radius_mean  3 - area_mean 6 -  concavity_mean 26 - concavity_worst\n",
      "\n",
      "\n",
      "The scikit-learn accuracy of SVM: 95.80 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.88372093  0.93023256  0.94117647  0.92941176  0.97619048]\n",
      "CV Accuracy: 0.93 (+/- 0.06)\n",
      "[[90  0]\n",
      " [ 6 47]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.94      1.00      0.97        90\n",
      "  Malignant       1.00      0.89      0.94        53\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n",
      "The scikit-learn accuracy of RFC: 96.50 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.90697674  0.97674419  0.91764706  0.94117647  0.96428571]\n",
      "CV Accuracy: 0.94 (+/- 0.05)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.94      1.00      0.97        90\n",
      "  Malignant       1.00      0.89      0.94        53\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n",
      "[[89  1]\n",
      " [ 4 49]]\n",
      "The scikit-learn accuracy of DT: 93.71 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.87209302  0.95348837  0.90588235  0.94117647  0.94047619]\n",
      "CV Accuracy: 0.92 (+/- 0.06)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.96      0.99      0.97        90\n",
      "  Malignant       0.98      0.92      0.95        53\n",
      "\n",
      "avg / total       0.97      0.97      0.96       143\n",
      "\n",
      "[[83  7]\n",
      " [ 2 51]]\n",
      "The scikit-learn accuracy of NB: 95.80 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.93023256  0.93023256  0.91764706  0.94117647  0.98809524]\n",
      "CV Accuracy: 0.94 (+/- 0.05)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.98      0.92      0.95        90\n",
      "  Malignant       0.88      0.96      0.92        53\n",
      "\n",
      "avg / total       0.94      0.94      0.94       143\n",
      "\n",
      "[[86  4]\n",
      " [ 2 51]]\n",
      "The scikit-learn accuracy of MLP: 91.61 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.91860465  0.95348837  0.92941176  0.94117647  0.95238095]\n",
      "CV Accuracy: 0.94 (+/- 0.03)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.98      0.96      0.97        90\n",
      "  Malignant       0.93      0.96      0.94        53\n",
      "\n",
      "avg / total       0.96      0.96      0.96       143\n",
      "\n",
      "[[79 11]\n",
      " [ 1 52]]\n",
      "The scikit-learn accuracy of LR: 94.41 %\n",
      "Cross Validation Accuracy:\n",
      "[ 0.88372093  0.93023256  0.95294118  0.94117647  0.97619048]\n",
      "CV Accuracy: 0.94 (+/- 0.06)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.99      0.88      0.93        90\n",
      "  Malignant       0.83      0.98      0.90        53\n",
      "\n",
      "avg / total       0.93      0.92      0.92       143\n",
      "\n",
      "[[88  2]\n",
      " [ 6 47]]\n"
     ]
    }
   ],
   "source": [
    "######################### SelectKBest, ANOVA F-value Features ###################################################\n",
    "\n",
    "select3 = feature_selection.SelectKBest(f_classif,k=10)\n",
    "selected3 = select.fit(X_train, Y_train)\n",
    "X_train_selected3 = selected3.transform(X_train)\n",
    "X_test_selected3 = selected3.transform(X_test)\n",
    "print('X_train feature selected shape is: {}'.format(X_train_selected3.shape))\n",
    "print('(30 features range from 0-29 due to Python language)')\n",
    "mask = selected3.get_support()\n",
    "print('Selected 10 (k) feature column numbers with ANOVA F-values:')\n",
    "print(mask)\n",
    "idxs_selected = selected3.get_support(indices=True)\n",
    "\n",
    "print(idxs_selected)\n",
    "\n",
    "print(\"Feature p-values with ANOVA selectkbest\")\n",
    "pval= np.sort(selected.pvalues_)\n",
    "pvalnames = np.argsort(selected.pvalues_)\n",
    "print(pval)\n",
    "print(\"Feature p-values ranked from lowest to highest:\")\n",
    "print(pvalnames)\n",
    "print(\"10 (k) selected features from most to least significant:\")\n",
    "print('27 - concave points_worst',\n",
    "       '7 - concave points_mean',\n",
    "      '22 - perimeter_worst',\n",
    "      '20 - radius_worst',\n",
    "      '2 - perimeter_mean' ,\n",
    "      '23 - area_worst',\n",
    "      '0 - radius_mean ',\n",
    "      '3 - area_mean', \n",
    "      '6 -  concavity_mean',\n",
    "     '26 - concavity_worst')\n",
    "\n",
    "############### SelectKBest with Scikit-learn Algoritms #################################\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "svm.fit(X_train_selected3, Y_train)\n",
    "print('The scikit-learn accuracy of SVM: {:.2f}'.format(svm.score(X_test_selected3, Y_test)*100),  '%')\n",
    "scores = cross_val_score(svm, X_train_selected2, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "predictions = svm.predict(X_test_selected3)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "\n",
    "rfc.fit(X_train_selected3, Y_train)\n",
    "print('The scikit-learn accuracy of RFC: {:.2f}'.format(rfc.score(X_test_selected3, Y_test)*100),  '%')\n",
    "scores = cross_val_score(rfc, X_train_selected3, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = rfc.predict(X_test_selected3)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "dt.fit(X_train_selected3, Y_train)\n",
    "print('The scikit-learn accuracy of DT: {:.2f}'.format(dt.score(X_test_selected3, Y_test)*100),  '%')\n",
    "scores = cross_val_score(dt, X_train_selected3, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = dt.predict(X_test_selected3)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "nb.fit(X_train_selected3, Y_train)\n",
    "print('The scikit-learn accuracy of NB: {:.2f}'.format(nb.score(X_test_selected3, Y_test)*100),  '%')\n",
    "scores = cross_val_score(nb, X_train_selected3, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = nb.predict(X_test_selected3)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "mlp.fit(X_train_selected3, Y_train)\n",
    "print('The scikit-learn accuracy of MLP: {:.2f}'.format(mlp.score(X_test_selected3, Y_test)*100),  '%')\n",
    "scores = cross_val_score(mlp, X_train_selected3, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = mlp.predict(X_test_selected3)\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "\n",
    "logreg.fit(X_train_selected3, Y_train)\n",
    "print('The scikit-learn accuracy of LR: {:.2f}'.format(logreg.score(X_test_selected3, Y_test)*100),  '%')\n",
    "scores = cross_val_score(logreg, X_train_selected3, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"CV Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(classification_report(Y_test, predictions, target_names=target_names))\n",
    "predictions = logreg.predict(X_test_selected3)\n",
    "print(confusion_matrix(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PostLR_L1norm_selection =data[['texture_mean', 'compactness_mean', 'concave points_mean', 'symmetry_mean', 'radius_se', 'texture_se',\n",
    "                  'perimeter_se', 'compactness_se', 'concavity_se','concave points_se','symmetry_se', 'fractal_dimension_se',\n",
    "                  'perimeter_worst', 'smoothness_worst', 'compactness_worst', 'symmetry_worst', 'fractal_dimension_worst']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn LR Accuracy with Post-algorithm Feature Selection: 93.00699300699301\n",
      "Cross Validation Accuracy:\n",
      "[0.91860465 0.89534884 0.89411765 0.90588235 0.92857143]\n",
      "Accuracy: 0.91 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(PostLR_L1norm_selection, Y, test_size=0.25, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "score = logreg.score(X_test, Y_test)\n",
    "print(\"Scikit-learn LR Accuracy with Post-algorithm Feature Selection:\", score*100)\n",
    "scores = cross_val_score(logreg, X_train, Y_train, cv=5)\n",
    "print('Cross Validation Accuracy:')\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
