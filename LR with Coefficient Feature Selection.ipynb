{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sort\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pandas import DataFrame\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\Hannah\\Desktop\\Research Project\\data.csv\")\n",
    "data = data.drop([\"Unnamed: 32\", \"id\"],1)\n",
    "\n",
    "X = data.values[:,2:-1].astype('float64')\n",
    "X = (X - np.mean(X, axis =0)) /  np.std(X, axis = 0)\n",
    "X = np.hstack([np.ones((X.shape[0], 1)),X]) \n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "Y = data[\"diagnosis\"].map({'M':1,'B':0})\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_select = data[['compactness_mean', 'concavity_mean', 'concave points_mean',\n",
    "       'radius_se', 'perimeter_se', 'area_se',  'texture_worst',\n",
    "        'area_worst', 'concave points_worst', 'symmetry_worst']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 10)\n",
      "Scikit-learn LR Accuracy with Post-algorithm Feature Selection: 97.2027972028 %\n",
      "Scikit-learn LR with Post-Algorithm Selection Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.97      0.99      0.98        90\n",
      "  Malignant       0.98      0.94      0.96        53\n",
      "\n",
      "avg / total       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_select, Y, test_size=0.25, random_state=0)\n",
    "print(X_train.shape)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "score = logreg.score(X_test, Y_test)\n",
    "print(\"Scikit-learn LR Accuracy with Post-algorithm Feature Selection:\",score*100, \"%\")\n",
    "print(\"Scikit-learn LR with Post-Algorithm Selection Report:\")\n",
    "target_names = ['Benign', 'Malignant']\n",
    "print(classification_report(Y_test, prediction, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hypothesis(theta, x):   \n",
    "    return Sigmoid(x @ theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost_Function(X,Y,theta,m):\n",
    "    hi = Hypothesis(theta, x)\n",
    "    _y = Y.reshape(-1, 1)\n",
    "    J = 1/float(m) * np.sum(-_y * np.log(hi) - (1-_y) * np.log(1-hi))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost_Function_Derivative(X,Y,theta,m,alpha):\n",
    "    hi = Hypothesis(theta,X)\n",
    "    _y = Y.reshape(-1, 1)\n",
    "    J = alpha/float(m) * X.T @ (hi - _y)\n",
    "    return J\n",
    "\n",
    "def Gradient_Descent(X,Y,theta,m,alpha):\n",
    "    new_theta = theta - Cost_Function_Derivative(X,Y,theta,m,alpha)\n",
    "    return new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hannah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy:  77.6223776224 %\n",
      "Scikit-learn Accuracy score 77.622378 %\n",
      "Confusion Matrix: \n",
      " [[87  3]\n",
      " [29 24]]\n",
      "\n",
      "\n",
      "LR Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.75      0.97      0.84        90\n",
      "  Malignant       0.89      0.45      0.60        53\n",
      "\n",
      "avg / total       0.80      0.78      0.75       143\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a50f053ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Accuracy(theta):\n",
    "    correct = 0\n",
    "    length = len(X_test)\n",
    "    prediction = (Hypothesis(theta, X_test) > 0.5) #replaced round to use predictions which are correct is ranging between the Y shape below\n",
    "    _y = Y_test.reshape(-1, 1)\n",
    "    correct = prediction == _y\n",
    "    my_accuracy = (np.sum(correct) / length)*100\n",
    "    print ('LR Accuracy: ', my_accuracy, \"%\")\n",
    "    print(\"Scikit-learn Accuracy score %f\" % (accuracy_score(Y_test, prediction)*100),\"%\")\n",
    "    \n",
    "    #Confusion matrix and F1 scoring\n",
    "    cm= confusion_matrix(Y_test, prediction)\n",
    "    print(\"Confusion Matrix:\", \"\\n\", cm)\n",
    "    sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "    print('\\n')\n",
    "    print(\"LR Report:\")\n",
    "    target_names = ['Benign', 'Malignant']\n",
    "    print(classification_report(Y_test, prediction, target_names=target_names))\n",
    "\n",
    "\n",
    "def Logistic_Regression(X,Y,alpha,theta,num_iters):\n",
    "    m = len(Y)\n",
    "    for x in range(num_iters):\n",
    "        new_theta = Gradient_Descent(X,Y,theta,m,alpha)\n",
    "        theta = new_theta\n",
    "        if x % 100 == 0:\n",
    "            print #('theta: ', theta)    \n",
    "            print #('cost: ', Cost_Function(X,Y,theta,m))\n",
    "    Accuracy(theta)\n",
    "\n",
    "\n",
    "ep = .012   #sets initial theta to random non zero numbers +/- .012 specifically is arbitrary\n",
    "\n",
    "initial_theta = np.random.rand(X_train.shape[1],1) * 2 * ep - ep\n",
    "alpha = 0.9\n",
    "iterations = 100000\n",
    "Logistic_Regression(X_train,Y_train,alpha,initial_theta,iterations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
