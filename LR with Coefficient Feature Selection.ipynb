{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sort\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pandas import DataFrame\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\Hannah\\Desktop\\Research Project\\data.csv\")\n",
    "data = data.drop([\"Unnamed: 32\", \"id\"],1)\n",
    "\n",
    "X = data.values[:,2:-1].astype('float64')\n",
    "X = (X - np.mean(X, axis =0)) /  np.std(X, axis = 0)\n",
    "X = np.hstack([np.ones((X.shape[0], 1)),X]) \n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "Y = data[\"diagnosis\"].map({'M':1,'B':0})\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_select = data[['radius_mean', 'texture_mean', 'perimeter_mean', 'smoothness_mean', 'concavity_mean',\n",
    "                 'concave points_mean', 'symmetry_mean', 'texture_se', 'area_se', 'smoothness_se', 'perimeter_worst',\n",
    "                 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst' , 'fractal_dimension_worst']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 17)\n",
      "Scikit-learn LR Accuracy with Post-algorithm Feature Selection: 90.2097902098 %\n",
      "Scikit-learn LR with Post-Algorithm Selection Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.93      0.91      0.92        90\n",
      "  Malignant       0.85      0.89      0.87        53\n",
      "\n",
      "avg / total       0.90      0.90      0.90       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_select, Y, test_size=0.25, random_state=0)\n",
    "print(X_train.shape)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "score = logreg.score(X_test, Y_test)\n",
    "print(\"Scikit-learn LR Accuracy with Post-algorithm Feature Selection:\",score*100, \"%\")\n",
    "print(\"Scikit-learn LR with Post-Algorithm Selection Report:\")\n",
    "target_names = ['Benign', 'Malignant']\n",
    "print(classification_report(Y_test, prediction, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hypothesis(theta, x):   \n",
    "    return Sigmoid(x @ theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost_Function(X,Y,theta,m):\n",
    "    hi = Hypothesis(theta, x)\n",
    "    _y = Y.reshape(-1, 1)\n",
    "    J = 1/float(m) * np.sum(-_y * np.log(hi) - (1-_y) * np.log(1-hi))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost_Function_Derivative(X,Y,theta,m,alpha):\n",
    "    hi = Hypothesis(theta,X)\n",
    "    _y = Y.reshape(-1, 1)\n",
    "    J = alpha/float(m) * X.T @ (hi - _y)\n",
    "    return J\n",
    "\n",
    "def Gradient_Descent(X,Y,theta,m,alpha):\n",
    "    new_theta = theta - Cost_Function_Derivative(X,Y,theta,m,alpha)\n",
    "    return new_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hannah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy:  83.9160839161 %\n",
      "Scikit-learn Accuracy score 83.916084 %\n",
      "Confusion Matrix: \n",
      " [[70 20]\n",
      " [ 3 50]]\n",
      "\n",
      "\n",
      "LR Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Benign       0.96      0.78      0.86        90\n",
      "  Malignant       0.71      0.94      0.81        53\n",
      "\n",
      "avg / total       0.87      0.84      0.84       143\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d7f9e3128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Accuracy(theta):\n",
    "    correct = 0\n",
    "    length = len(X_test)\n",
    "    prediction = (Hypothesis(theta, X_test) > 0.5) #replaced round to use predictions which are correct is ranging between the Y shape below\n",
    "    _y = Y_test.reshape(-1, 1)\n",
    "    correct = prediction == _y\n",
    "    my_accuracy = (np.sum(correct) / length)*100\n",
    "    print ('LR Accuracy: ', my_accuracy, \"%\")\n",
    "    print(\"Scikit-learn Accuracy score %f\" % (accuracy_score(Y_test, prediction)*100),\"%\")\n",
    "    \n",
    "    #Confusion matrix and F1 scoring\n",
    "    cm= confusion_matrix(Y_test, prediction)\n",
    "    print(\"Confusion Matrix:\", \"\\n\", cm)\n",
    "    sns.heatmap(cm,annot=True,fmt=\"d\")\n",
    "    print('\\n')\n",
    "    print(\"LR Report:\")\n",
    "    target_names = ['Benign', 'Malignant']\n",
    "    print(classification_report(Y_test, prediction, target_names=target_names))\n",
    "\n",
    "\n",
    "def Logistic_Regression(X,Y,alpha,theta,num_iters):\n",
    "    m = len(Y)\n",
    "    for x in range(num_iters):\n",
    "        new_theta = Gradient_Descent(X,Y,theta,m,alpha)\n",
    "        theta = new_theta\n",
    "        if x % 100 == 0:\n",
    "            print #('theta: ', theta)    \n",
    "            print #('cost: ', Cost_Function(X,Y,theta,m))\n",
    "    Accuracy(theta)\n",
    "\n",
    "\n",
    "ep = .012   #sets initial theta to random non zero numbers +/- .012 specifically is arbitrary\n",
    "\n",
    "initial_theta = np.random.rand(X_train.shape[1],1) * 2 * ep - ep\n",
    "alpha = 0.9\n",
    "iterations = 100000\n",
    "Logistic_Regression(X_train,Y_train,alpha,initial_theta,iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
